{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Aim: to recognize the tone of a Mandarin sylable from an audio recording.\n",
    "\n",
    "TODO: Add detailed introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection\n",
    "\n",
    "Wiktionary.com contains pronunciation examples for a large selection of Mandarin expressions. In this section, Mandarin expressions with available pronunciations are identified, and the audio files are downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_html(soup):\n",
    "    \"\"\"\n",
    "    Remove all html with the unwanted classes\n",
    "    \"\"\"\n",
    "    unwanted_classes = ['sister-wikipedia', 'thumb', 'reference', 'cited-source']\n",
    "    for tag in soup.find_all(True, {'class': unwanted_classes}):\n",
    "        tag.extract()\n",
    "        \n",
    "def parse_next_page_links(soup, category):\n",
    "    \"\"\"\n",
    "    Return url of the next page for multi-page lists.\n",
    "    \"\"\"\n",
    "    link_tags = soup.find('div', {'id': 'mw-pages'}).find_all('a', {'title': category})\n",
    "    return [link['href'] for link in link_tags if link.text == 'next page']\n",
    "\n",
    "def parse_category_words(soup):\n",
    "    \"\"\"\n",
    "    Return list of (linked) words from a single category page of Wiktionary\n",
    "    \"\"\"\n",
    "    words_content = soup.find('div', {'id': 'mw-pages'}).find('div', {'class': 'mw-content-ltr'})\n",
    "    words = [word.text for word in words_content.find_all('a')]\n",
    "    return words\n",
    "\n",
    "def get_category_data(soup, category):\n",
    "    \"\"\"\n",
    "    Return all (linked) words from a Wiktionary category including multiple pages\n",
    "    \"\"\"\n",
    "    words = []\n",
    "    next_page_links = parse_next_page_links(soup, category)\n",
    "    while len(next_page_links) > 0:\n",
    "        words += parse_category_words(soup)\n",
    "        response = session.get('https://en.wiktionary.org/' + next_page_links[0])\n",
    "        soup = BeautifulSoup(response.text.replace('>\\n<', '><'), 'html.parser')\n",
    "        clean_html(soup)\n",
    "        next_page_links = parse_next_page_links(soup, category)\n",
    "    words += parse_category_words(soup)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['鞄', '一', '一下兒', '一些', '一共', '一再', '一切', '一向', '一塊兒', '一定']\n"
     ]
    }
   ],
   "source": [
    "#Get html for page 1 of Category:Mandarin terms with audio links\n",
    "session = requests.Session()\n",
    "category = \"Category:Mandarin terms with audio links\"\n",
    "response = session.get(\"https://en.wiktionary.org/wiki/{}\".format(category))\n",
    "soup = BeautifulSoup(response.text.replace('>\\n<', '><'), 'html.parser')\n",
    "\n",
    "#Extract words from html\n",
    "clean_html(soup)\n",
    "words = get_category_data(soup, category)\n",
    "\n",
    "#Remove words that are not Chinese characters\n",
    "words = [w for w in words if not re.search(r'[^\\u4e00-\\u9fff]+', w)]\n",
    "\n",
    "#Print the first 10 words as examples\n",
    "print(words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pronunciation_source(word, session):\n",
    "    \"\"\"\n",
    "    Return the pinyin and link to audio pronunciation example for a \n",
    "    Mandarin word from Wiktionary\n",
    "    \"\"\"\n",
    "    source = None\n",
    "    response = session.get(\"https://en.wiktionary.org/wiki/{}\".format(word))\n",
    "    soup = BeautifulSoup(response.text.replace('>\\n<', '><'), 'html.parser')\n",
    "    pronunciations_box = soup.find(\"div\", {\"data-toggle-category\": \"pronunciations\"})\n",
    "    \n",
    "    pinyin_tag = pronunciations_box.find_all(\"a\", text=\"Pinyin\")[0]\n",
    "    pinyin = [a for a in pinyin_tag.find_parent().find_parent().find_parent().find_all(\"a\") if a.text != \"Pinyin\"][0].text\n",
    "    \n",
    "    mandarin_li = [li for li in pronunciations_box.find_all(\"li\") if li.find_all(\"a\", text=\"Mandarin\")]\n",
    "    if mandarin_li[0].find(\"source\"):\n",
    "        source = mandarin_li[0].find(\"source\")[\"src\"]\n",
    "    return pinyin, source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6dc4b8b47aa4a09a571f5f04dfb009f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4932.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Collect pinyins and audio sources for Mandarin words with audio links\n",
    "sources = []\n",
    "pinyins = []\n",
    "for word in tqdm(words):\n",
    "    pinyin, source = get_pronunciation_source(word, session)\n",
    "    sources.append(source)\n",
    "    pinyins.append(pinyin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"word\": words, \"pinyin\": pinyins, \"source\": sources})\n",
    "df = df.dropna()\n",
    "\n",
    "with open(\"dataset\", \"wb\") as file:\n",
    "    pickle.dump(df, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08fef61f0ccd47a38e0171bd94e6a79b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4910.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(\"data/\"):\n",
    "    os.mkdir(\"data/\")\n",
    "for word, source in tqdm(list(zip(df.word.tolist(), df.source.tolist()))):\n",
    "    if not os.path.isfile(\"data/{}.ogg\".format(word)):\n",
    "        response = session.get(\"http:\" + source)\n",
    "        if response.status_code == 200:\n",
    "            with open(\"data/{}.ogg\".format(word), \"wb\") as file:\n",
    "                file.write(response.content)\n",
    "        else:\n",
    "            print(response.status_code)\n",
    "            print(\"Error downloading {}.ogg\".format(word))\n",
    "        #Avoid too many requests\n",
    "        time.sleep(0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "### Pinyin preprocessing\n",
    "\n",
    "The ground truth data for supervised learning algorithms should be numbers (1, 2, 3, or 4) representing the Mandarin tone. Therefore, these tone numbers must first be calculated from the pinyin pronunciation guides downloaded from Wiktionary. For example, yīgòng should be converted to \\[1, 4\\]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "from itertools import groupby, cycle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset\", \"rb\") as file:\n",
    "    df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tones(pinyin, hanzi):\n",
    "    \"\"\"\n",
    "    Returns a list of integers representing the tones for a pinyin word\n",
    "    \"\"\"\n",
    "    num_chars = len(hanzi)\n",
    "    tones = []\n",
    "    found_tones = re.findall(\"[āēīōūǖĀĒĪŌŪǕáéíóúǘÁÉÍÓÚǗǎěǐǒǔǚǍĚǏǑǓǙàèìòùǜÀÈÌÒÙǛ]\", \n",
    "                             pinyin)\n",
    "    if len(found_tones) == num_chars:\n",
    "        for sylable in found_tones:\n",
    "            if re.search(\"[āēīōūǖĀĒĪŌŪǕ]\", sylable):\n",
    "                tones.append(1)\n",
    "            elif re.search(\"[áéíóúǘÁÉÍÓÚǗ]\", sylable):\n",
    "                tones.append(2)\n",
    "            elif re.search(\"[ǎěǐǒǔǚǍĚǏǑǓǙ]\", sylable):\n",
    "                tones.append(3)\n",
    "            elif re.search(\"[àèìòùǜÀÈÌÒÙǛ]\", sylable):\n",
    "                tones.append(4)\n",
    "    elif len(found_tones) < num_chars:\n",
    "        for sylable in found_tones:\n",
    "            if re.search(\"[āēīōūǖĀĒĪŌŪǕ]\", sylable):\n",
    "                tones.append(1)\n",
    "            elif re.search(\"[áéíóúǘÁÉÍÓÚǗ]\", sylable):\n",
    "                tones.append(2)\n",
    "            elif re.search(\"[ǎěǐǒǔǚǍĚǏǑǓǙ]\", sylable):\n",
    "                tones.append(3)\n",
    "            elif re.search(\"[àèìòùǜÀÈÌÒÙǛ]\", sylable):\n",
    "                tones.append(4)\n",
    "        for i in range(num_chars - len(found_tones)):\n",
    "            tones.append(5)\n",
    "            \n",
    "    return tones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tones(\"yīgòng\", \"一共\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, the actual pronounced tone does not match the pinyin guide; however, these cases follow specific rules. For example, 可以 has pinyin kěyǐ, indicating the tone pair \\[3, 3\\], but the actual pronounciation is \\[2, 3\\]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_sequence(li): \n",
    "    \"\"\"\n",
    "    A helper function for tone adjustment\n",
    "    Takes a list of integers as its argument\n",
    "    Returns a list of tuples containing subsequences of l that \n",
    "    increase by 1 for each index \n",
    "    e.g., [1, 2, 3, 1, 2, 2, 1, 1] returns [(1, 2, 3), (1, 2)]\n",
    "    \"\"\"\n",
    "    temp_list = cycle(li) \n",
    "    next(temp_list) \n",
    "    groups = groupby(li, key = lambda j: j + 1 == next(temp_list)) \n",
    "    for k, v in groups: \n",
    "        if k: \n",
    "            yield tuple(v) + (next((next(groups)[1])), ) \n",
    "\n",
    "def tone_adjustment(tones, hanzi):\n",
    "    \"\"\"\n",
    "    Adjusts a list of tones according to the rules for mandarin tone \n",
    "    adjustment and return the corrected list of tones\n",
    "    (e.g., [3, 3] --> [2, 3])\n",
    "    \"\"\"\n",
    "    three_indexes = [i for i, v in enumerate(tones) if v ==3]\n",
    "    if len(three_indexes) > 0:\n",
    "        #Find the indexes of adjacent groups of third tones.\n",
    "        three_chains = list(group_sequence(three_indexes))\n",
    "        for three_chain in three_chains:\n",
    "            tones[min(three_chain):max(three_chain) + 1] = [2]*(max(three_chain) - min(three_chain)) + [3]\n",
    "    if \"不\" in hanzi and hanzi[-1] != \"不\":\n",
    "        if tones[hanzi.index(\"不\") + 1] == 4:\n",
    "            tones[hanzi.index(\"不\")] = 2\n",
    "    if \"一\" in hanzi and hanzi[-1] != \"一\":\n",
    "        following_char = hanzi[hanzi.index(\"一\")+1]\n",
    "        if following_char not in [\"一\", \"二\", \"三\", \"四\", \"五\", \"六\", \"七\", \"八\", \"九\"]:\n",
    "            if tones[hanzi.index(\"一\")+1] == 4:\n",
    "                tones[hanzi.index(\"一\")] = 2\n",
    "            else:\n",
    "                tones[hanzi.index(\"一\")] = 4\n",
    "    return tones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hanzi = \"可以\"\n",
    "pinyin = \"kěyǐ\"\n",
    "tones = get_tones(pinyin, hanzi)\n",
    "tone_adjustment(tones, hanzi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pinyin</th>\n",
       "      <th>source</th>\n",
       "      <th>tones</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>鞄</td>\n",
       "      <td>páo</td>\n",
       "      <td>//upload.wikimedia.org/wikipedia/commons/1/16/...</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>一</td>\n",
       "      <td>yī</td>\n",
       "      <td>//upload.wikimedia.org/wikipedia/commons/b/b0/...</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>一下兒</td>\n",
       "      <td>yīxiàr</td>\n",
       "      <td>//upload.wikimedia.org/wikipedia/commons/7/7c/...</td>\n",
       "      <td>[2, 4, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>一些</td>\n",
       "      <td>yīxiē</td>\n",
       "      <td>//upload.wikimedia.org/wikipedia/commons/5/5e/...</td>\n",
       "      <td>[4, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>一共</td>\n",
       "      <td>yīgòng</td>\n",
       "      <td>//upload.wikimedia.org/wikipedia/commons/5/51/...</td>\n",
       "      <td>[2, 4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word  pinyin                                             source      tones\n",
       "0    鞄     páo  //upload.wikimedia.org/wikipedia/commons/1/16/...        [2]\n",
       "1    一      yī  //upload.wikimedia.org/wikipedia/commons/b/b0/...        [1]\n",
       "2  一下兒  yīxiàr  //upload.wikimedia.org/wikipedia/commons/7/7c/...  [2, 4, 5]\n",
       "3   一些   yīxiē  //upload.wikimedia.org/wikipedia/commons/5/5e/...     [4, 1]\n",
       "4   一共  yīgòng  //upload.wikimedia.org/wikipedia/commons/5/51/...     [2, 4]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"tones\"] = df.apply(lambda x: tone_adjustment(get_tones(x[1], x[0]), \n",
    "                                          x[0]), axis=1)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
